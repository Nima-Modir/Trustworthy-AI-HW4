{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## $$\\color{red}{\\text{Nima Modirkiasaraee - Q3}}$$\n",
    "## $$\\color{red}{\\text{810102339}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import necessary libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part1: Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>educational-num</th>\n",
       "      <th>race</th>\n",
       "      <th>gender</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>native-country</th>\n",
       "      <th>income</th>\n",
       "      <th>...</th>\n",
       "      <th>occupation_Protective-serv</th>\n",
       "      <th>occupation_Sales</th>\n",
       "      <th>occupation_Tech-support</th>\n",
       "      <th>occupation_Transport-moving</th>\n",
       "      <th>relationship_Husband</th>\n",
       "      <th>relationship_Not-in-family</th>\n",
       "      <th>relationship_Other-relative</th>\n",
       "      <th>relationship_Own-child</th>\n",
       "      <th>relationship_Unmarried</th>\n",
       "      <th>relationship_Wife</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25</td>\n",
       "      <td>226802</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38</td>\n",
       "      <td>89814</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28</td>\n",
       "      <td>336951</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>44</td>\n",
       "      <td>160323</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7688</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>18</td>\n",
       "      <td>103497</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>34</td>\n",
       "      <td>198693</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>29</td>\n",
       "      <td>227026</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>63</td>\n",
       "      <td>104626</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3103</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>24</td>\n",
       "      <td>369667</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>55</td>\n",
       "      <td>104996</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 43 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  fnlwgt  educational-num  race  gender  capital-gain  capital-loss  \\\n",
       "0   25  226802                7     0       1             0             0   \n",
       "1   38   89814                9     1       1             0             0   \n",
       "2   28  336951               12     1       1             0             0   \n",
       "3   44  160323               10     0       1          7688             0   \n",
       "4   18  103497               10     1       0             0             0   \n",
       "5   34  198693                6     1       1             0             0   \n",
       "6   29  227026                9     0       1             0             0   \n",
       "7   63  104626               15     1       1          3103             0   \n",
       "8   24  369667               10     1       0             0             0   \n",
       "9   55  104996                4     1       1             0             0   \n",
       "\n",
       "   hours-per-week  native-country  income  ...  occupation_Protective-serv  \\\n",
       "0              40               0       0  ...                       False   \n",
       "1              50               0       0  ...                       False   \n",
       "2              40               0       1  ...                        True   \n",
       "3              40               0       1  ...                       False   \n",
       "4              30               0       0  ...                       False   \n",
       "5              30               0       0  ...                       False   \n",
       "6              40               0       0  ...                       False   \n",
       "7              32               0       1  ...                       False   \n",
       "8              40               0       0  ...                       False   \n",
       "9              10               0       0  ...                       False   \n",
       "\n",
       "   occupation_Sales  occupation_Tech-support  occupation_Transport-moving  \\\n",
       "0             False                    False                        False   \n",
       "1             False                    False                        False   \n",
       "2             False                    False                        False   \n",
       "3             False                    False                        False   \n",
       "4             False                    False                        False   \n",
       "5             False                    False                        False   \n",
       "6             False                    False                        False   \n",
       "7             False                    False                        False   \n",
       "8             False                    False                        False   \n",
       "9             False                    False                        False   \n",
       "\n",
       "   relationship_Husband  relationship_Not-in-family  \\\n",
       "0                 False                       False   \n",
       "1                  True                       False   \n",
       "2                  True                       False   \n",
       "3                  True                       False   \n",
       "4                 False                       False   \n",
       "5                 False                        True   \n",
       "6                 False                       False   \n",
       "7                  True                       False   \n",
       "8                 False                       False   \n",
       "9                  True                       False   \n",
       "\n",
       "   relationship_Other-relative  relationship_Own-child  \\\n",
       "0                        False                    True   \n",
       "1                        False                   False   \n",
       "2                        False                   False   \n",
       "3                        False                   False   \n",
       "4                        False                    True   \n",
       "5                        False                   False   \n",
       "6                        False                   False   \n",
       "7                        False                   False   \n",
       "8                        False                   False   \n",
       "9                        False                   False   \n",
       "\n",
       "   relationship_Unmarried  relationship_Wife  \n",
       "0                   False              False  \n",
       "1                   False              False  \n",
       "2                   False              False  \n",
       "3                   False              False  \n",
       "4                   False              False  \n",
       "5                   False              False  \n",
       "6                    True              False  \n",
       "7                   False              False  \n",
       "8                    True              False  \n",
       "9                   False              False  \n",
       "\n",
       "[10 rows x 43 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('data.csv')\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 48842 entries, 0 to 48841\n",
      "Data columns (total 43 columns):\n",
      " #   Column                        Non-Null Count  Dtype\n",
      "---  ------                        --------------  -----\n",
      " 0   age                           48842 non-null  int64\n",
      " 1   fnlwgt                        48842 non-null  int64\n",
      " 2   educational-num               48842 non-null  int64\n",
      " 3   race                          48842 non-null  int64\n",
      " 4   gender                        48842 non-null  int64\n",
      " 5   capital-gain                  48842 non-null  int64\n",
      " 6   capital-loss                  48842 non-null  int64\n",
      " 7   hours-per-week                48842 non-null  int64\n",
      " 8   native-country                48842 non-null  int64\n",
      " 9   income                        48842 non-null  int64\n",
      " 10  workclass_Federal-gov         48842 non-null  bool \n",
      " 11  workclass_Local-gov           48842 non-null  bool \n",
      " 12  workclass_Never-worked        48842 non-null  bool \n",
      " 13  workclass_Private             48842 non-null  bool \n",
      " 14  workclass_Self-emp-inc        48842 non-null  bool \n",
      " 15  workclass_Self-emp-not-inc    48842 non-null  bool \n",
      " 16  workclass_State-gov           48842 non-null  bool \n",
      " 17  workclass_Without-pay         48842 non-null  bool \n",
      " 18  marital_status_divorced       48842 non-null  bool \n",
      " 19  marital_status_married        48842 non-null  bool \n",
      " 20  marital_status_separated      48842 non-null  bool \n",
      " 21  marital_status_unmarried      48842 non-null  bool \n",
      " 22  marital_status_widowed        48842 non-null  bool \n",
      " 23  occupation_Adm-clerical       48842 non-null  bool \n",
      " 24  occupation_Armed-Forces       48842 non-null  bool \n",
      " 25  occupation_Craft-repair       48842 non-null  bool \n",
      " 26  occupation_Exec-managerial    48842 non-null  bool \n",
      " 27  occupation_Farming-fishing    48842 non-null  bool \n",
      " 28  occupation_Handlers-cleaners  48842 non-null  bool \n",
      " 29  occupation_Machine-op-inspct  48842 non-null  bool \n",
      " 30  occupation_Other-service      48842 non-null  bool \n",
      " 31  occupation_Priv-house-serv    48842 non-null  bool \n",
      " 32  occupation_Prof-specialty     48842 non-null  bool \n",
      " 33  occupation_Protective-serv    48842 non-null  bool \n",
      " 34  occupation_Sales              48842 non-null  bool \n",
      " 35  occupation_Tech-support       48842 non-null  bool \n",
      " 36  occupation_Transport-moving   48842 non-null  bool \n",
      " 37  relationship_Husband          48842 non-null  bool \n",
      " 38  relationship_Not-in-family    48842 non-null  bool \n",
      " 39  relationship_Other-relative   48842 non-null  bool \n",
      " 40  relationship_Own-child        48842 non-null  bool \n",
      " 41  relationship_Unmarried        48842 non-null  bool \n",
      " 42  relationship_Wife             48842 non-null  bool \n",
      "dtypes: bool(33), int64(10)\n",
      "memory usage: 5.3 MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>educational-num</th>\n",
       "      <th>race</th>\n",
       "      <th>gender</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>native-country</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>48842.000000</td>\n",
       "      <td>4.884200e+04</td>\n",
       "      <td>48842.000000</td>\n",
       "      <td>48842.000000</td>\n",
       "      <td>48842.000000</td>\n",
       "      <td>48842.000000</td>\n",
       "      <td>48842.000000</td>\n",
       "      <td>48842.000000</td>\n",
       "      <td>48842.000000</td>\n",
       "      <td>48842.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>38.643585</td>\n",
       "      <td>1.896641e+05</td>\n",
       "      <td>10.078089</td>\n",
       "      <td>0.855043</td>\n",
       "      <td>0.668482</td>\n",
       "      <td>1079.067626</td>\n",
       "      <td>87.502314</td>\n",
       "      <td>40.422382</td>\n",
       "      <td>0.102576</td>\n",
       "      <td>0.239282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>13.710510</td>\n",
       "      <td>1.056040e+05</td>\n",
       "      <td>2.570973</td>\n",
       "      <td>0.352061</td>\n",
       "      <td>0.470764</td>\n",
       "      <td>7452.019058</td>\n",
       "      <td>403.004552</td>\n",
       "      <td>12.391444</td>\n",
       "      <td>0.303407</td>\n",
       "      <td>0.426649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>17.000000</td>\n",
       "      <td>1.228500e+04</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>28.000000</td>\n",
       "      <td>1.175505e+05</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>37.000000</td>\n",
       "      <td>1.781445e+05</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>48.000000</td>\n",
       "      <td>2.376420e+05</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>90.000000</td>\n",
       "      <td>1.490400e+06</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>99999.000000</td>\n",
       "      <td>4356.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                age        fnlwgt  educational-num          race  \\\n",
       "count  48842.000000  4.884200e+04     48842.000000  48842.000000   \n",
       "mean      38.643585  1.896641e+05        10.078089      0.855043   \n",
       "std       13.710510  1.056040e+05         2.570973      0.352061   \n",
       "min       17.000000  1.228500e+04         1.000000      0.000000   \n",
       "25%       28.000000  1.175505e+05         9.000000      1.000000   \n",
       "50%       37.000000  1.781445e+05        10.000000      1.000000   \n",
       "75%       48.000000  2.376420e+05        12.000000      1.000000   \n",
       "max       90.000000  1.490400e+06        16.000000      1.000000   \n",
       "\n",
       "             gender  capital-gain  capital-loss  hours-per-week  \\\n",
       "count  48842.000000  48842.000000  48842.000000    48842.000000   \n",
       "mean       0.668482   1079.067626     87.502314       40.422382   \n",
       "std        0.470764   7452.019058    403.004552       12.391444   \n",
       "min        0.000000      0.000000      0.000000        1.000000   \n",
       "25%        0.000000      0.000000      0.000000       40.000000   \n",
       "50%        1.000000      0.000000      0.000000       40.000000   \n",
       "75%        1.000000      0.000000      0.000000       45.000000   \n",
       "max        1.000000  99999.000000   4356.000000       99.000000   \n",
       "\n",
       "       native-country        income  \n",
       "count    48842.000000  48842.000000  \n",
       "mean         0.102576      0.239282  \n",
       "std          0.303407      0.426649  \n",
       "min          0.000000      0.000000  \n",
       "25%          0.000000      0.000000  \n",
       "50%          0.000000      0.000000  \n",
       "75%          0.000000      0.000000  \n",
       "max          1.000000      1.000000  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part2: Training the base model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training a model on the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.862212516208285\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.93      0.91     11233\n",
      "           1       0.74      0.64      0.68      3420\n",
      "\n",
      "    accuracy                           0.86     14653\n",
      "   macro avg       0.82      0.78      0.80     14653\n",
      "weighted avg       0.86      0.86      0.86     14653\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X = data.drop('income', axis=1)\n",
    "y = data['income']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "model = RandomForestClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "report = classification_report(y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy}')\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zemel fairness: -0.10582537751920096\n",
      "Disparate impact: 1.1279354156935382\n"
     ]
    }
   ],
   "source": [
    "test_data = pd.concat([X_test, y_test], axis = 1)\n",
    "test_data['predict'] = model.predict(X_test)\n",
    "women_data = test_data[test_data['gender'] == 0]\n",
    "men_data = test_data[test_data['gender'] == 1]\n",
    "Zemel_Fairness = len(men_data[men_data['predict'] == men_data['income']]) / len(men_data) - len(women_data[women_data['predict'] == women_data['income']]) / len(women_data)\n",
    "Disparate_Impact = (len(women_data[women_data['predict'] == women_data['income']]) / len(women_data)) /  (len(men_data[men_data['predict'] == men_data['income']]) / len(men_data))\n",
    "print (f'Zemel fairness: {Zemel_Fairness}')\n",
    "print(f'Disparate impact: {Disparate_Impact}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Removing the sensitive attribute (gender)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8633726881867194\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.93      0.91     11233\n",
      "           1       0.74      0.64      0.69      3420\n",
      "\n",
      "    accuracy                           0.86     14653\n",
      "   macro avg       0.82      0.78      0.80     14653\n",
      "weighted avg       0.86      0.86      0.86     14653\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X = data.drop(['income', 'gender'], axis=1)\n",
    "y = data['income']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "model = RandomForestClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "report = classification_report(y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy}')\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zemel fairness: -0.1034747114701643\n",
      "Disparate impact: 1.1248011716292052\n"
     ]
    }
   ],
   "source": [
    "test_data = pd.concat([X_test, y_test], axis = 1)\n",
    "test_data['predict'] = model.predict(X_test)\n",
    "X = data.drop('income', axis=1)\n",
    "X_train, X_test = train_test_split(X, test_size=0.3, random_state=42)\n",
    "test_data['gender'] = X_test['gender']\n",
    "women_data = test_data[test_data['gender'] == 0]\n",
    "men_data = test_data[test_data['gender'] == 1]\n",
    "Zemel_Fairness = len(men_data[men_data['predict'] == men_data['income']]) / len(men_data) - len(women_data[women_data['predict'] == women_data['income']]) / len(women_data)\n",
    "Disparate_Impact = (len(women_data[women_data['predict'] == women_data['income']]) / len(women_data)) /  (len(men_data[men_data['predict'] == men_data['income']]) / len(men_data))\n",
    "print (f'Zemel fairness: {Zemel_Fairness}')\n",
    "print(f'Disparate impact: {Disparate_Impact}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part3: Implementing the fair model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = data.drop('income', axis=1)\n",
    "y = data['income']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "model = RandomForestClassifier()\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.concat([X_train, y_train], axis = 1)\n",
    "predictions = model.predict(X_train)\n",
    "probs = np.max(model.predict_proba(X_train), axis = 1)\n",
    "train_data['predict'] = predictions\n",
    "train_data['predict_prob'] = probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "CP = train_data[(train_data['gender'] == 1) & (train_data['income'] == 1)].sort_values('predict_prob')\n",
    "CD = train_data[(train_data['gender'] == 0) & (train_data['income'] == 0)].sort_values('predict_prob', ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n: 1478.6186200239842\n"
     ]
    }
   ],
   "source": [
    "women_numbers = len(train_data[train_data['gender'] == 0])\n",
    "men_numbers = len(train_data[train_data['gender'] == 1])\n",
    "women_high_income = len(train_data[(train_data['gender'] == 0) & (train_data['predict'] == 1)])\n",
    "men_high_income = len(train_data[(train_data['gender'] == 1) & (train_data['predict'] == 1)])\n",
    "n = ((women_numbers * men_high_income) - (men_numbers * women_high_income)) / (women_numbers + men_numbers)\n",
    "print (f'n: {n}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "CP_indices = CP.index[0: round(n)]\n",
    "CD_indices = CD.index[0: round(n)]\n",
    "income_CP = train_data.loc[CP_indices, 'income'].values\n",
    "income_CD = train_data.loc[CD_indices, 'income'].values\n",
    "train_data.loc[CP_indices, 'income'] = income_CD\n",
    "train_data.loc[CD_indices, 'income'] = income_CP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8569576196000819\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.94      0.91     11233\n",
      "           1       0.74      0.59      0.66      3420\n",
      "\n",
      "    accuracy                           0.86     14653\n",
      "   macro avg       0.81      0.76      0.78     14653\n",
      "weighted avg       0.85      0.86      0.85     14653\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_train = train_data.drop(['income', 'predict', 'predict_prob'], axis=1)\n",
    "y_train = train_data['income']\n",
    "\n",
    "model = RandomForestClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "report = classification_report(y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy}')\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zemel fairness: -0.0760850239819546\n",
      "Disparate impact: 1.091473740349702\n"
     ]
    }
   ],
   "source": [
    "test_data = pd.concat([X_test, y_test], axis = 1)\n",
    "test_data['predict'] = model.predict(X_test)\n",
    "women_data = test_data[test_data['gender'] == 0]\n",
    "men_data = test_data[test_data['gender'] == 1]\n",
    "Zemel_Fairness = len(men_data[men_data['predict'] == men_data['income']]) / len(men_data) - len(women_data[women_data['predict'] == women_data['income']]) / len(women_data)\n",
    "Disparate_Impact = (len(women_data[women_data['predict'] == women_data['income']]) / len(women_data)) /  (len(men_data[men_data['predict'] == men_data['income']]) / len(men_data))\n",
    "print (f'Zemel fairness: {Zemel_Fairness}')\n",
    "print(f'Disparate impact: {Disparate_Impact}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bonus Section: Another method for fairness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/200], Loss: 0.3624\n",
      "Epoch [20/200], Loss: 0.3440\n",
      "Epoch [30/200], Loss: 0.3287\n",
      "Epoch [40/200], Loss: 0.3208\n",
      "Epoch [50/200], Loss: 0.3154\n",
      "Epoch [60/200], Loss: 0.3111\n",
      "Epoch [70/200], Loss: 0.3076\n",
      "Epoch [80/200], Loss: 0.3048\n",
      "Epoch [90/200], Loss: 0.3026\n",
      "Epoch [100/200], Loss: 0.3010\n",
      "Epoch [110/200], Loss: 0.2996\n",
      "Epoch [120/200], Loss: 0.2985\n",
      "Epoch [130/200], Loss: 0.2974\n",
      "Epoch [140/200], Loss: 0.2964\n",
      "Epoch [150/200], Loss: 0.2955\n",
      "Epoch [160/200], Loss: 0.2946\n",
      "Epoch [170/200], Loss: 0.2937\n",
      "Epoch [180/200], Loss: 0.2929\n",
      "Epoch [190/200], Loss: 0.2921\n",
      "Epoch [200/200], Loss: 0.2913\n",
      "Test Loss: 0.3047\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "X = data.drop(columns=['income'])\n",
    "y = data['income']\n",
    "\n",
    "X_train, X_test, y_train, y_test= train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "X_train = torch.tensor(X_train, dtype=torch.float32)\n",
    "X_test = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_train = torch.tensor(y_train.values, dtype=torch.float32).view(-1, 1)\n",
    "y_test = torch.tensor(y_test.values, dtype=torch.float32).view(-1, 1)\n",
    "\n",
    "class Predictor(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(Predictor, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, 64)\n",
    "        self.fc2 = nn.Linear(64, 1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.sigmoid(self.fc2(x))\n",
    "        return x\n",
    "\n",
    "input_dim = X_train.shape[1]\n",
    "predictor = Predictor(input_dim)\n",
    "predictor_optimizer = optim.Adam(predictor.parameters(), lr=0.01)\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "num_epochs = 200\n",
    "lambda_reg = 0.1\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    predictor.train()\n",
    "\n",
    "    y_pred = predictor(X_train)\n",
    "    \n",
    "    predictor_optimizer.zero_grad()\n",
    "    loss = criterion(y_pred, y_train)\n",
    "    loss.backward()\n",
    "    predictor_optimizer.step()\n",
    "    \n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
    "\n",
    "predictor.eval()\n",
    "with torch.no_grad():\n",
    "    y_pred_test = predictor(X_test)\n",
    "    test_loss = criterion(y_pred_test, y_test)\n",
    "    print(f'Test Loss: {test_loss.item():.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8627\n"
     ]
    }
   ],
   "source": [
    "predictor.eval()\n",
    "with torch.no_grad():\n",
    "    y_pred_test = predictor(X_test)\n",
    "    y_pred_test = (y_pred_test >= 0.5).float() \n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred_test)\n",
    "print(f'Accuracy: {accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zemel fairness: -0.10757654202140743\n",
      "Disparate impact: 1.1300684920308173\n"
     ]
    }
   ],
   "source": [
    "X = data.drop(['income'], axis=1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "test_data = pd.concat([X_test, y_test], axis = 1)\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "test_data['predict'] = predictor(torch.tensor(np.array(X_test), dtype = torch.float32)).detach().numpy()\n",
    "test_data['predict'] = torch.tensor((test_data['predict'] >= 0.5).values).float().numpy()\n",
    "women_data = test_data[test_data['gender'] == 0]\n",
    "men_data = test_data[test_data['gender'] == 1]\n",
    "Zemel_Fairness = len(men_data[men_data['predict'] == men_data['income']]) / len(men_data) - len(women_data[women_data['predict'] == women_data['income']]) / len(women_data)\n",
    "Disparate_Impact = (len(women_data[women_data['predict'] == women_data['income']]) / len(women_data)) /  (len(men_data[men_data['predict'] == men_data['income']]) / len(men_data))\n",
    "print (f'Zemel fairness: {Zemel_Fairness}')\n",
    "print(f'Disparate impact: {Disparate_Impact}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/200], Loss: -0.1345, Income Loss: 0.3676, Adversary Loss: 0.6276\n",
      "Epoch [20/200], Loss: -0.1373, Income Loss: 0.3492, Adversary Loss: 0.6082\n",
      "Epoch [30/200], Loss: -0.1493, Income Loss: 0.3409, Adversary Loss: 0.6127\n",
      "Epoch [40/200], Loss: -0.1569, Income Loss: 0.3412, Adversary Loss: 0.6226\n",
      "Epoch [50/200], Loss: -0.1623, Income Loss: 0.3317, Adversary Loss: 0.6175\n",
      "Epoch [60/200], Loss: -0.1666, Income Loss: 0.3238, Adversary Loss: 0.6129\n",
      "Epoch [70/200], Loss: -0.1706, Income Loss: 0.3229, Adversary Loss: 0.6168\n",
      "Epoch [80/200], Loss: -0.1736, Income Loss: 0.3203, Adversary Loss: 0.6174\n",
      "Epoch [90/200], Loss: -0.1759, Income Loss: 0.3188, Adversary Loss: 0.6184\n",
      "Epoch [100/200], Loss: -0.1777, Income Loss: 0.3159, Adversary Loss: 0.6170\n",
      "Epoch [110/200], Loss: -0.1792, Income Loss: 0.3147, Adversary Loss: 0.6174\n",
      "Epoch [120/200], Loss: -0.1805, Income Loss: 0.3135, Adversary Loss: 0.6175\n",
      "Epoch [130/200], Loss: -0.1816, Income Loss: 0.3121, Adversary Loss: 0.6171\n",
      "Epoch [140/200], Loss: -0.1826, Income Loss: 0.3111, Adversary Loss: 0.6172\n",
      "Epoch [150/200], Loss: -0.1835, Income Loss: 0.3104, Adversary Loss: 0.6174\n",
      "Epoch [160/200], Loss: -0.1844, Income Loss: 0.3095, Adversary Loss: 0.6174\n",
      "Epoch [170/200], Loss: -0.1851, Income Loss: 0.3089, Adversary Loss: 0.6175\n",
      "Epoch [180/200], Loss: -0.1858, Income Loss: 0.3083, Adversary Loss: 0.6176\n",
      "Epoch [190/200], Loss: -0.1865, Income Loss: 0.3077, Adversary Loss: 0.6177\n",
      "Epoch [200/200], Loss: -0.1872, Income Loss: 0.3070, Adversary Loss: 0.6176\n",
      "Test Loss: 0.3182\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "X = data.drop(columns=['income', 'gender'])\n",
    "y = data['income']\n",
    "sensitive_attribute = data['gender']\n",
    "\n",
    "X_train, X_test, y_train, y_test, sensitive_train, sensitive_test = train_test_split(X, y, sensitive_attribute, test_size=0.3, random_state=42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "X_train = torch.tensor(X_train, dtype=torch.float32)\n",
    "X_test = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_train = torch.tensor(y_train.values, dtype=torch.float32).view(-1, 1)\n",
    "y_test = torch.tensor(y_test.values, dtype=torch.float32).view(-1, 1)\n",
    "sensitive_train = torch.tensor(sensitive_train.values, dtype=torch.float32).view(-1, 1)\n",
    "sensitive_test = torch.tensor(sensitive_test.values, dtype=torch.float32).view(-1, 1)\n",
    "\n",
    "class Predictor(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(Predictor, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, 64)\n",
    "        self.fc2 = nn.Linear(64, 1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.sigmoid(self.fc2(x))\n",
    "        return x\n",
    "\n",
    "class Adversary(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Adversary, self).__init__()\n",
    "        self.fc1 = nn.Linear(1, 32)\n",
    "        self.fc2 = nn.Linear(32, 1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.sigmoid(self.fc2(x))\n",
    "        return x\n",
    "\n",
    "input_dim = X_train.shape[1]\n",
    "predictor = Predictor(input_dim)\n",
    "adversary = Adversary()\n",
    "predictor_optimizer = optim.Adam(predictor.parameters(), lr=0.01)\n",
    "adversary_optimizer = optim.Adam(adversary.parameters(), lr=0.01)\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "num_epochs = 200\n",
    "lambda_reg = 0.8\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    total_loss = 0\n",
    "    predictor.train()\n",
    "    adversary.train()\n",
    "\n",
    "    y_pred = predictor(X_train)\n",
    "    \n",
    "    adversary_optimizer.zero_grad()\n",
    "    sensitive_pred = adversary(y_pred.detach())\n",
    "    adversary_loss = criterion(sensitive_pred, sensitive_train)\n",
    "    adversary_loss.backward()\n",
    "    adversary_optimizer.step()\n",
    "    \n",
    "    predictor_optimizer.zero_grad()\n",
    "    income_loss = criterion(y_pred, y_train)\n",
    "    sensitive_pred = adversary(y_pred)\n",
    "    adv_loss = criterion(sensitive_pred, sensitive_train)\n",
    "    total_loss = income_loss - lambda_reg * adv_loss\n",
    "    total_loss.backward()\n",
    "    predictor_optimizer.step()\n",
    "    \n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {total_loss.item():.4f}, Income Loss: {income_loss.item():.4f}, Adversary Loss: {adv_loss.item():.4f}')\n",
    "\n",
    "predictor.eval()\n",
    "with torch.no_grad():\n",
    "    y_pred_test = predictor(X_test)\n",
    "    test_loss = criterion(y_pred_test, y_test)\n",
    "    print(f'Test Loss: {test_loss.item():.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8596\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "predictor.eval()\n",
    "with torch.no_grad():\n",
    "    y_pred_test = predictor(X_test)\n",
    "    y_pred_test = (y_pred_test >= 0.5).float()  \n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred_test)\n",
    "print(f'Accuracy: {accuracy:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zemel fairness: -0.10117559170230628\n",
      "Disparate impact: 1.1224803198550088\n"
     ]
    }
   ],
   "source": [
    "X = data.drop(['income', 'gender'], axis=1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "test_data = pd.concat([X_test, y_test], axis = 1)\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "test_data['predict'] = predictor(torch.tensor(np.array(X_test), dtype = torch.float32)).detach().numpy()\n",
    "X = data.drop('income', axis=1)\n",
    "X_train, X_test = train_test_split(X, test_size=0.3, random_state=42)\n",
    "test_data['gender'] = X_test['gender']\n",
    "test_data['predict'] = torch.tensor((test_data['predict'] >= 0.5).values).float().numpy()\n",
    "women_data = test_data[test_data['gender'] == 0]\n",
    "men_data = test_data[test_data['gender'] == 1]\n",
    "Zemel_Fairness = len(men_data[men_data['predict'] == men_data['income']]) / len(men_data) - len(women_data[women_data['predict'] == women_data['income']]) / len(women_data)\n",
    "Disparate_Impact = (len(women_data[women_data['predict'] == women_data['income']]) / len(women_data)) /  (len(men_data[men_data['predict'] == men_data['income']]) / len(men_data))\n",
    "print (f'Zemel fairness: {Zemel_Fairness}')\n",
    "print(f'Disparate impact: {Disparate_Impact}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
